# Checklist for TA-MISBEHAVIOURS from [Codethink](https://codethinklabs.gitlab.io/trustable/trustable/print_page.html)

* How has the list of misbehaviours varied over time? <br>
    Answer:  
* How confident can we be that this list is comprehensive? <br>
    Answer:  
* How well do the misbehaviours map to the expectations? <br>
    Answer:  
* Could some participants have incentives to manipulate information? <br>
    Answer:  
* Could there be whole categories of misbehaviours still undiscovered? <br>
    Answer:  
* Can we identify misbehaviours that have been understood but not specified? <br>
    Answer:  
* Can we identify some new misbehaviours, right now? <br>
    Answer:  
* Is every misbehaviour represented by at least one fault induction test? <br>
    Answer:  
* Are fault inductions used to demonstrate that tests which usually pass can and do fail appropriately? <br>
    Answer:  
* Are all the fault induction results actually collected? <br>
    Answer:  
* Are the results evaluated? <br>
    Answer:  
* Do input analysis findings on verifiable tool or component claims and features identify additional misbehaviours or support existing mitigations? <br>
    Answer:  